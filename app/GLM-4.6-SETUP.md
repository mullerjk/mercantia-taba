# ğŸš€ GLM-4.6 com Unsloth no Docker

## VisÃ£o Geral

Este setup utiliza o Unsloth para rodar o GLM-4.6 de forma otimizada em um container Docker.

**BenefÃ­cios:**
- âœ… 4-6x mais rÃ¡pido que versÃ£o base
- âœ… Usa ~8GB VRAM (em vez de 180GB+)
- âœ… Ambiente isolado e reproduzÃ­vel
- âœ… Jupyter Lab integrado

## ğŸ“‹ PrÃ©-requisitos

- Docker instalado
- ~15GB de espaÃ§o em disco
- Mac com Apple Silicon ou Intel

## ğŸš€ Como Usar

### OpÃ§Ã£o 1: Script AutomÃ¡tico (Recomendado)

```bash
./run-unsloth.sh
```

Este script:
- Inicia o container com as portas corretas
- Monta seu workspace
- Mostra o link do Jupyter Lab

### OpÃ§Ã£o 2: Comando Manual

```bash
docker run -it --rm --platform linux/amd64 \
  -p 8888:8888 \
  -p 22:22 \
  -v ~/Sites/taba/app:/workspace \
  unsloth/unsloth
```

## ğŸŒ Acessar Jupyter Lab

1. O container mostrarÃ¡ um link como: `http://127.0.0.1:8888/?token=...`
2. Copie e abra no navegador
3. Crie um novo notebook Python

## ğŸ“ Exemplo: Usar GLM-4.6

Dentro do Jupyter Lab, crie uma cÃ©lula com:

```python
from unsloth import FastLanguageModel
import torch

# Carregar modelo
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/glm-4-9b-gguf",
    max_seq_length=2048,
    dtype=torch.float16,
    load_in_4bit=True,
)

# Modo de inferÃªncia
FastLanguageModel.for_inference(model)

# Gerar resposta
prompt = "OlÃ¡! Qual Ã© a capital do Brasil?"
inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=100)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(response)
```

## ğŸ“š Recursos Adicionais

- [DocumentaÃ§Ã£o Unsloth](https://docs.unsloth.ai/)
- [GLM-4.6 Setup Guide](https://docs.unsloth.ai/models/glm-4.6-how-to-run-locally)
- [Hugging Face Model Card](https://huggingface.co/unsloth/glm-4-9b-gguf)

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

### Fine-tuning (Treinamento)

```python
from unsloth import FastLanguageModel

# Setup para treinamento
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/glm-4-9b-gguf",
    max_seq_length=2048,
    dtype=torch.float16,
    load_in_4bit=True,
)

# Habilitar LoRA para fine-tuning eficiente
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    lora_alpha=16,
    lora_dropout=0.05,
    bias="none",
    use_gradient_checkpointing="unsloth",
    random_state=42,
)
```

### Parar o Container

Pressione `Ctrl+C` no terminal

### Remover Imagem Docker

```bash
docker rmi unsloth/unsloth
```

## ğŸ› Troubleshooting

**Problema:** Container nÃ£o inicia
- SoluÃ§Ã£o: Verifique espaÃ§o em disco

**Problema:** Jupyter nÃ£o mostra token
- SoluÃ§Ã£o: Aguarde 30-60 segundos

**Problema:** Erro de memÃ³ria
- SoluÃ§Ã£o: Reduz `max_seq_length` ou use `load_in_8bit=True`

---

**Criado em:** 1 de novembro de 2025
